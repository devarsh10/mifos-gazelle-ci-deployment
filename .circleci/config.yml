# CircleCI 2.1 configuration for Mifos Gazelle deployment automation

version: 2.1

# Define executors: Environments where jobs will run
executors:
  # Ubuntu 20.04 executor using CircleCI's base image
  ubuntu-2004:
    docker:
      - image: cimg/base:stable # Using stable base image
    resource_class: large # Use a larger resource class for Docker operations

# Define jobs: Individual tasks in the workflow
jobs:
  deploy-and-verify-mifos-gazelle:
    executor: ubuntu-2004 # Use the defined Ubuntu 20.04 executor
    steps:
      - checkout # Step to check out the repository code into the working directory
      - setup_remote_docker: # This step provisions a dedicated Docker environment
          docker_layer_caching: true # Enable Docker layer caching for faster builds

      - run:
          name: Install Dependencies (Docker, Docker Compose, Kubectl, K3s)
          command: |
            echo "Updating apt package list..."
            sudo apt-get update -y

            echo "Installing necessary packages for Docker..."
            sudo apt-get install -y apt-transport-https ca-certificates curl gnupg-agent software-properties-common

            echo "Adding Docker's official GPG key..."
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

            echo "Setting up the stable Docker repository..."
            sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

            echo "Updating apt package list again after adding Docker repo..."
            sudo apt-get update -y

            echo "Installing Docker CE CLI and Containerd..."
            # Docker daemon is handled by setup_remote_docker, but we ensure the CLI is available
            sudo apt-get install -y docker-ce-cli containerd.io

            echo "Installing Docker Compose (version 1.29.2)..."
            sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
            sudo chmod +x /usr/local/bin/docker-compose

            echo "Verifying Docker and Docker Compose installation..."
            docker --version
            docker-compose --version

            echo "Installing K3s (lightweight Kubernetes cluster)..."
            # Install k3s, make kubeconfig readable by non-root, and prevent it from starting as a service immediately
            # We'll start it manually in the next step.
            # Set K3S_KUBECONFIG_MODE to ensure the kubeconfig file is readable.
            # The --docker flag will be used when starting the server, so no need for snapshotter here.
            curl -sfL https://get.k3s.io | INSTALL_K3S_SKIP_ENABLE=true K3S_KUBECONFIG_MODE="644" sh -

            echo "Installing kubectl (Kubernetes command-line tool)..."
            # K3s installs its own kubectl, but we ensure the standard one is available and linked
            # The K3s install script should have already symlinked kubectl to /usr/local/bin/kubectl
            kubectl version --client

      - run:
          name: Start K3s Cluster
          command: |
            echo "Setting up KUBECONFIG..."
            mkdir -p ~/.kube

            echo "Starting K3s server with Docker runtime..."
            # Start k3s server in the background, using the Docker daemon provided by setup_remote_docker
            sudo k3s server --docker &

            echo "Waiting for k3s.yaml to be created..."
            # Wait for the k3s.yaml file to appear, up to 60 seconds
            timeout 60s bash -c '
              for i in $(seq 1 6); do
                if [ -f /etc/rancher/k3s/k3s.yaml ]; then
                  echo "k3s.yaml found."
                  break
                else
                  echo "Attempt $i: k3s.yaml not found yet. Retrying in 10 seconds..."
                  sleep 10
                fi
                if [ $i -eq 6 ]; then
                  echo "Timeout: k3s.yaml did not appear after 60 seconds."
                  exit 1
                fi
              done
            '
            sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
            sudo chmod 600 ~/.kube/config
            export KUBECONFIG=~/.kube/config
            echo "KUBECONFIG set to $KUBECONFIG"

            echo "Waiting for K3s server to be ready..."
            # Give k3s a moment to start its API server
            sleep 10
            timeout 300s bash -c '
              for i in $(seq 1 30); do
                # Use the explicit KUBECONFIG path for kubectl
                if kubectl --kubeconfig=~/.kube/config get nodes -o wide | grep -q " Ready"; then
                  echo "K3s node is ready."
                  break
                else
                  echo "Attempt $i: K3s node not ready yet. Retrying in 10 seconds..."
                  sleep 10
                fi
                if [ $i -eq 30 ]; then
                  echo "Timeout: K3s node did not become ready after 5 minutes."
                  exit 1
                fi
              done
            '
            kubectl get nodes # Verify node is visible

      - run:
          name: Run Mifos Gazelle Deployment Script
          command: |
            echo "Executing Mifos Gazelle's ./run.sh script..."
            # Ensure KUBECONFIG is set for this step
            export KUBECONFIG=~/.kube/config
            ./run.sh
            echo "Mifos Gazelle deployment script execution completed."

      - run:
          name: Wait for Kubernetes Pods to be Ready
          command: |
            echo "Waiting for all Kubernetes pods in the 'default' namespace to reach 'Running' state..."
            # Ensure KUBECONFIG is set for this step
            export KUBECONFIG=~/.kube/config
            # Loop for up to 10 minutes (60 attempts * 10 seconds)
            timeout 600s bash -c '
              for i in $(seq 1 60); do
                # Get names of pods that are NOT in "Running" state
                UNREADY_PODS=$(kubectl get pods -n default -o json | jq -r ".items[] | select(.status.phase != \"Running\") | .metadata.name")
                if [ -z "$UNREADY_PODS" ]; then
                  echo "All pods in default namespace are running."
                  break # Exit loop if all pods are running
                else
                  echo "Attempt $i: Still waiting for these pods to be Running: $UNREADY_PODS"
                  kubectl get pods -n default # Show current pod status
                  sleep 10 # Wait 10 seconds before next check
                fi
                if [ $i -eq 60 ]; then
                  echo "Timeout: Not all pods in default namespace are running after 10 minutes."
                  exit 1 # Exit with error if timeout reached
                fi
              done
            '
            echo "All required Kubernetes pods are running."

      - run:
          name: Verify Deployment with Curl
          command: |
            echo "Attempting to retrieve URL for 'fineract-cn-api-gateway' service..."
            # Ensure KUBECONFIG is set for this step
            export KUBECONFIG=~/.kube/config

            SERVICE_URL=""
            ATTEMPTS=0
            MAX_ATTEMPTS=30 # Max 5 minutes (30 * 10 seconds) to get service URL

            while [ -z "$SERVICE_URL" ] && [ $ATTEMPTS -lt $MAX_ATTEMPTS ]; do
              echo "Attempt $((ATTEMPTS+1)): Getting service URL..."
              # Get the Node IP
              NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')
              # Get the NodePort for fineract-cn-api-gateway service
              SERVICE_NODEPORT=$(kubectl get service fineract-cn-api-gateway -n default -o jsonpath='{.spec.ports[?(@.name=="http")].nodePort}' 2>/dev/null)

              if [ -n "$NODE_IP" ] && [ -n "$SERVICE_NODEPORT" ]; then
                SERVICE_URL="http://$NODE_IP:$SERVICE_NODEPORT"
                echo "Constructed service URL: $SERVICE_URL"
              else
                echo "Node IP ($NODE_IP) or Service NodePort ($SERVICE_NODEPORT) not yet available. Retrying in 10 seconds..."
                sleep 10
              fi
              ATTEMPTS=$((ATTEMPTS+1))
            done

            if [ -z "$SERVICE_URL" ]; then
              echo "Error: Could not determine 'fineract-cn-api-gateway' service URL after multiple attempts."
              exit 1 # Fail the job if URL cannot be obtained
            fi

            echo "Mifos Gazelle API Gateway URL: $SERVICE_URL"

            echo "Performing health check curl to $SERVICE_URL/actuator/health..."
            # Perform a curl request to the health endpoint and capture the HTTP status code
            curl_status=$(curl -s -o /dev/null -w "%{http_code}" "$SERVICE_URL/actuator/health")
            echo "Curl to $SERVICE_URL/actuator/health returned HTTP status: $curl_status"

            # Check if the HTTP status code indicates success (2xx range)
            if [[ "$curl_status" -ge 200 && "$curl_status" -lt 300 ]]; then
              echo "Mifos Gazelle API Gateway is healthy (HTTP $curl_status). Deployment successful!"
            else
              echo "Error: Mifos Gazelle API Gateway did not return a healthy status (HTTP $curl_status). Deployment verification failed."
              exit 1 # Fail the job if health check is unsuccessful
            fi

# Define workflows: Orchestrate jobs
workflows:
  version: 2
  build-and-deploy-mifos-gazelle: # Name of the workflow
    jobs:
      - deploy-and-verify-mifos-gazelle # Run the defined job
